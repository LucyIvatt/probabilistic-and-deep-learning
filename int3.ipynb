{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Systems 3: Probabilistic and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Regression and classification (42 marks)\n",
    "1. Train and evaluate a least squares linear regression model predicting the value of\n",
    "variable D from variables A, B and C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line is needed to use matplotlib in Jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def least_squares_regression(data, train_size, pipeline):\n",
    "    # separates D as the target variable\n",
    "    X = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "\n",
    "    # Split the data into training/testing sets\n",
    "    X_train = X[:-train_size]\n",
    "    X_test = X[-train_size:]\n",
    "\n",
    "    # Split the targets into training/testing sets\n",
    "    y_train = y[:-train_size]\n",
    "    y_test = y[-train_size:]\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # The coefficients\n",
    "    print(\"Coefficients of A, B & C:\", pipeline.named_steps['LinearRegression'].coef_)\n",
    "\n",
    "    # The intercept\n",
    "    print(\"Intercept:\", pipeline.named_steps['LinearRegression'].intercept_)\n",
    "\n",
    "    # The mean squared error\n",
    "    print('Mean squared error: %.2f'\n",
    "        % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    # The coefficient of determination: \n",
    "    #   1 is perfect prediction\n",
    "    #   0 is as good as always predicting the mean output value (using the training data).\n",
    "    #   negative values are for a model that is worse than just predicting the mean.\n",
    "    print('Coefficient of determination (R2): %.2f'\n",
    "        % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\" * 32 + \" QUESTION 1 (a) \" + \"-\" * 32)\n",
    "\n",
    "# Loads the dataset (skipping the headers) and runs basic linear least squares regression.\n",
    "data = np.genfromtxt('data.csv', delimiter=',', skip_header=1, dtype=float)\n",
    "pipeline = Pipeline([('LinearRegression', LinearRegression())])\n",
    "least_squares_regression(data=data, pipeline=pipeline, train_size=75)\n",
    "\n",
    "print(\"-\" * 76)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Repeat the above task after carrying out in turn data normalisation, data scaling and\n",
    "their combination, and evaluate the benefits of each of these 3 types of data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\" * 32 + \" QUESTION 1 (b)\" + \"-\" * 32)\n",
    "\n",
    "# 1. Performs Data Normalisation\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "print(\"Normalizer:\")\n",
    "data = np.genfromtxt('data.csv', delimiter=',', skip_header=1, dtype=float)\n",
    "minmax_scaled_pipeline = Pipeline([('Normalizer', Normalizer()), ('LinearRegression', LinearRegression())])\n",
    "least_squares_regression(data=data, pipeline=minmax_scaled_pipeline, train_size=75)\n",
    "\n",
    "# 2. Performs Data Scaling\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Standard Scaler\n",
    "print(\"\\nScaler:\")\n",
    "data = np.genfromtxt('data.csv', delimiter=',', skip_header=1, dtype=float)\n",
    "std_scaled_pipeline = Pipeline([('Standard Scaler', StandardScaler()), ('LinearRegression', LinearRegression())])\n",
    "least_squares_regression(data=data, pipeline=std_scaled_pipeline, train_size=75)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Principal Component Analysis (8 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from itertools import combinations\n",
    "\n",
    "data = np.loadtxt('data.csv',delimiter=',',skiprows=1)\n",
    "\n",
    "# extend the table with 6 additional column consisting of the product of each pair of the original 4 variables A, B, C and D\n",
    "for i, j in combinations(range(4), 2):\n",
    "    data = np.hstack((data, np.atleast_2d(np.multiply(data[:, i], data[:, j])).T))\n",
    "\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "pca.fit(data)\n",
    "newData = pca.fit_transform(data)\n",
    "\n",
    "NewTotVar = 0\n",
    "for i, dim in enumerate(('PC1','PC2','PC3','PC4')):\n",
    "  Var2 = np.var(newData[:,i])\n",
    "  NewTotVar += Var2\n",
    "  print('Here is the sample variance for the {0} dimension'.format(dim))\n",
    "  print('var = {0}\\n\\n'.format(Var2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
